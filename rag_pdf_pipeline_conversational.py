import os
import re
import shutil
from dotenv import load_dotenv
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain.chains import ConversationalRetrievalChain

# ======================================
# 1ï¸âƒ£ í™˜ê²½ì„¤ì • ë° ìƒìˆ˜
# ======================================
load_dotenv()
api_key = os.getenv("UPSTAGE_API_KEY")
if not api_key:
    raise ValueError("âŒ .env íŒŒì¼ì— UPSTAGE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")

PDF_FOLDER = r"C:\Users\seogu\Documents\CampusFinder\PDFs"
DB_PATH = "pdf_chroma_db"

# ======================================
# 2ï¸âƒ£ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
# ======================================
def extract_text_from_pdfs(pdf_folder):
    pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith(".pdf")]
    if not pdf_files:
        raise FileNotFoundError("âŒ PDFs í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    print(f"ğŸ“„ ì´ {len(pdf_files)}ê°œì˜ PDF íŒŒì¼ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤.\n")
    all_texts = []

    for filename in pdf_files:
        pdf_path = os.path.join(pdf_folder, filename)
        reader = PdfReader(pdf_path)
        text = ""
        for page in reader.pages:
            content = page.extract_text()
            if content:
                text += content + "\n"

        # ì „ì²˜ë¦¬: ê³µë°±, ì¤„ë°”ê¿ˆ, íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
        text = re.sub(r"\s+", " ", text)
        text = re.sub(r"[\u200b\xa0]", " ", text)

        if text.strip():
            all_texts.append(f"[ë¬¸ì„œ: {filename}]\n{text.strip()}")
        else:
            print(f"âš ï¸ {filename}ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return all_texts

# ======================================
# 3ï¸âƒ£ ë²¡í„° DB ìƒì„±
# ======================================
def build_vector_db(texts):
    print("\nğŸ§  í…ìŠ¤íŠ¸ ë¶„í•  ë° ì„ë² ë”© ìƒì„± ì¤‘...")
    splitter = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=150)
    chunks = []
    for doc in texts:
        chunks.extend(splitter.split_text(doc))
    print(f"âœ‚ï¸ ì´ {len(chunks)}ê°œì˜ ì²­í¬ ìƒì„± ì™„ë£Œ")

    # ê¸°ì¡´ DB ì‚­ì œ
    if os.path.exists(DB_PATH):
        shutil.rmtree(DB_PATH)
        print("ğŸ—‘ ê¸°ì¡´ DB ì‚­ì œ ì™„ë£Œ")

    embeddings = UpstageEmbeddings(model="solar-embedding-1-large")
    vectorstore = Chroma.from_texts(texts=chunks, embedding=embeddings, persist_directory=DB_PATH)
    vectorstore.persist()
    print("âœ… ìƒˆë¡œìš´ ë²¡í„° DB ìƒì„± ì™„ë£Œ!")
    return vectorstore

# ======================================
# 4ï¸âƒ£ ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ í™•ì¥ (semantic reformulation)
# ======================================
def refine_query(query: str) -> str:
    # ì˜ë„ ê¸°ë°˜ ì§ˆë¬¸ ë³´ì •
    query = query.strip().lower()
    replacements = {
        "ì´ê²Œ ë­ì•¼": "ì •ì˜ì™€ ê°œë…ì„ ì„¤ëª…í•´ì¤˜",
        "ì´ê±´ ë­ì•¼": "ì •ì˜ì™€ ê°œë…ì„ ì•Œë ¤ì¤˜",
        "ì–´ë–»ê²Œ": "ì ˆì°¨ë‚˜ ë°©ë²•ì„ ì„¤ëª…í•´ì¤˜",
        "ì™œ": "ì´ìœ ì™€ ëª©ì ì„ ì•Œë ¤ì¤˜",
        "ë¹„êµ": "ì°¨ì´ì ì„ ì„¤ëª…í•´ì¤˜",
        "ê°™ì€ê°€": "ìœ ì‚¬ì ê³¼ ì°¨ì´ì ì„ ì•Œë ¤ì¤˜"
    }
    for key, val in replacements.items():
        if key in query:
            query += f" ({val})"
    return query

# ======================================
# 5ï¸âƒ£ ì±—ë´‡ ì‹¤í–‰
# ======================================
def run_conversational_rag():
    texts = extract_text_from_pdfs(PDF_FOLDER)
    vectorstore = build_vector_db(texts)

    llm = ChatUpstage(model="solar-pro")
    retriever = vectorstore.as_retriever(search_kwargs={"k": 8})

    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        return_source_documents=True,
        chain_type="stuff"
    )

    chat_history = []
    print("\nğŸ“ ìº í¼ìŠ¤ íŒŒì¸ë” ëŒ€í™”í˜• RAG ì±—ë´‡ ì‹œì‘!")
    print("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. (ì¢…ë£Œí•˜ë ¤ë©´ exit ì…ë ¥)\n")

    while True:
        query = input("â“ ì§ˆë¬¸: ").strip()
        if query.lower() in ["exit", "quit"]:
            print("ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # ì§ˆë¬¸ ì˜ë„ ë³´ì •
        refined = refine_query(query)
        try:
            result = qa_chain.invoke({"question": refined, "chat_history": chat_history})
            answer = result["answer"].strip()
            print(f"\nğŸ¤– ë‹µë³€:\n{answer}\n")
            chat_history.append((query, answer))
        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ======================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰
# ======================================
if __name__ == "__main__":
    run_conversational_rag()
