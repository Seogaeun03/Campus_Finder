import os
from dotenv import load_dotenv
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
import shutil

# ======================================
# ğŸ”¹ 1. í™˜ê²½ ì„¤ì •
# ======================================

load_dotenv()  # .env íŒŒì¼ ë¡œë“œ
api_key = os.getenv("UPSTAGE_API_KEY")

if not api_key:
    raise ValueError("âŒ .env íŒŒì¼ì— 'UPSTAGE_API_KEY'ê°€ ì—†ìŠµë‹ˆë‹¤.")

PDF_FOLDER = r"C:\Users\seogu\Documents\CampusFinder\PDFs"
DB_PATH = "pdf_chroma_db"

# ======================================
# ğŸ”¹ 2. PDF ì½ê¸° í•¨ìˆ˜
# ======================================

def extract_text_from_pdfs(pdf_folder):
    pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith(".pdf")]
    if not pdf_files:
        raise FileNotFoundError("âŒ PDFs í´ë” ì•ˆì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    print(f"ğŸ“„ ì´ {len(pdf_files)}ê°œì˜ PDF íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n")

    all_texts = []

    for filename in pdf_files:
        file_path = os.path.join(pdf_folder, filename)
        print(f"ğŸ” {filename} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")

        reader = PdfReader(file_path)
        text = ""
        for page in reader.pages:
            content = page.extract_text()
            if content:
                text += content + "\n"

        # PDF ì´ë¦„ íƒœê·¸ ì¶”ê°€
        if text.strip():
            all_texts.append(f"[ë¬¸ì„œ: {filename}]\n{text.strip()}")
        else:
            print(f"âš ï¸ {filename}ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    return all_texts

# ======================================
# ğŸ”¹ 3. ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•
# ======================================

def build_vector_db(texts):
    print("\nğŸ§  í…ìŠ¤íŠ¸ ë¶„í•  ë° ì„ë² ë”© ìƒì„± ì¤‘...")

    splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=200)
    chunks = []
    for doc in texts:
        chunks.extend(splitter.split_text(doc))

    print(f"âœ‚ï¸ ì´ {len(chunks)}ê°œì˜ ì²­í¬ ìƒì„± ì™„ë£Œ")

    # ê¸°ì¡´ DB ì‚­ì œ
    if os.path.exists(DB_PATH):
        shutil.rmtree(DB_PATH)
        print("ğŸ—‘ ê¸°ì¡´ Chroma DB ì‚­ì œ ì™„ë£Œ")

    embeddings = UpstageEmbeddings(model="solar-embedding-1-large")

    vectorstore = Chroma.from_texts(
        texts=chunks,
        embedding=embeddings,
        persist_directory=DB_PATH
    )
    vectorstore.persist()
    print("âœ… ë²¡í„° DB ìƒì„± ì™„ë£Œ!")

    return vectorstore

# ======================================
# ğŸ”¹ 4. RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹¤í–‰
# ======================================

def run_rag_chatbot(vectorstore):
    llm = ChatUpstage(model="solar-pro")
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

    print("\nğŸ“ ìº í¼ìŠ¤ íŒŒì¸ë” PDF RAG ì±—ë´‡ ì‹œì‘!")
    print("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ exit ì…ë ¥)\n")

    while True:
        query = input("â“ ì§ˆë¬¸: ").strip()
        if query.lower() in ["exit", "quit"]:
            print("ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        try:
            result = qa_chain.invoke({"query": query})
            print(f"\nğŸ¤– ë‹µë³€:\n{result['result']}\n")
        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ======================================
# ğŸš€ ì‹¤í–‰
# ======================================

if __name__ == "__main__":
    texts = extract_text_from_pdfs(PDF_FOLDER)
    vectorstore = build_vector_db(texts)
    run_rag_chatbot(vectorstore)
