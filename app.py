import os
import shutil
import streamlit as st
from dotenv import load_dotenv
from langchain_community.vectorstores import Chroma
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA

# ====================================
# ğŸŒŸ ê¸°ë³¸ ì„¤ì •
# ====================================

st.set_page_config(
    page_title="ğŸ“ ìº í¼ìŠ¤ íŒŒì¸ë” RAG ì±—ë´‡",
    page_icon="ğŸ“",
    layout="wide",
)

st.markdown(
    """
    <style>
    .main {
        background-color: #f8f9fc;
    }
    .stTextInput>div>div>input {
        border-radius: 12px;
        border: 1px solid #ccc;
        padding: 8px;
    }
    .stChatMessage {
        border-radius: 10px;
        padding: 12px;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# ====================================
# âš™ï¸ API í‚¤ ë¡œë“œ
# ====================================

load_dotenv()
api_key = os.getenv("UPSTAGE_API_KEY")
if not api_key:
    st.error("âŒ Upstage API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”!")
    st.stop()

# ====================================
# ğŸ§  ë²¡í„° DB ë¡œë“œ í•¨ìˆ˜
# ====================================

@st.cache_resource
def load_vectorstore():
    folder_path = "Result_crawling"
    documents = []

    # âœ… 1. í¬ë¡¤ë§ëœ í…ìŠ¤íŠ¸ ì½ê¸°
    for filename in os.listdir(folder_path):
        if filename.endswith(".txt"):
            with open(os.path.join(folder_path, filename), "r", encoding="utf-8") as f:
                documents.append(f.read())

    # âœ… 2. ì œëª© ë‹¨ìœ„ë¡œ ë¶„ë¦¬ (ì œëª© + ë³¸ë¬¸ ë¬¶ìŒ) + ê¸¸ì´ ì´ˆê³¼ ë°©ì§€
    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
    texts = []

    for doc in documents:
        sections = doc.split("[ì œëª©]")
        for section in sections:
            section = section.strip()
            if not section:
                continue

            lines = section.split("\n")
            title = lines[0].strip()
            body = "\n".join(lines[1:]).strip()
            combined = f"[ì œëª©]{title}\n{body}"

            # ğŸ‘‡ ë„ˆë¬´ ê¸´ ì²­í¬ëŠ” splitterë¡œ ë‹¤ì‹œ ì˜ë¼ì„œ ì¶”ê°€
            for chunk in splitter.split_text(combined):
                texts.append(chunk)


    # âœ… 3. ë²¡í„° ì„ë² ë”© ìƒì„±
    embedding = UpstageEmbeddings(model="solar-embedding-1-large")
    vectorstore = Chroma.from_texts(texts, embedding=embedding, persist_directory="chroma_db")
    return vectorstore

# ====================================
# ğŸš€ ì‚¬ì´ë“œë°” UI
# ====================================

st.sidebar.header("âš™ï¸ ì„¤ì • ë° ê¸°ëŠ¥")

# ğŸ” DB ë‹¤ì‹œ ìƒì„± ë²„íŠ¼
rebuild = st.sidebar.button("ğŸ” DB ë‹¤ì‹œ ìƒì„±í•˜ê¸°")
if rebuild:
    if os.path.exists("chroma_db"):
        shutil.rmtree("chroma_db")
        st.sidebar.success("âœ… ê¸°ì¡´ DB ì‚­ì œ ì™„ë£Œ! ìƒˆë¡œ ìƒì„± ì¤‘...")
    load_vectorstore.clear()
    vectorstore = load_vectorstore()
    st.sidebar.success("ğŸ‰ ìƒˆ DB ìƒì„± ì™„ë£Œ!")

# ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸
st.sidebar.markdown("---")
st.sidebar.markdown("ğŸ’¡ **ì˜ˆì‹œ ì§ˆë¬¸**")
example_questions = [
    "ì „ê³µ ë§ˆì´í¬ë¡œëª¨ë“ˆì´ë€?",
    "ì „ê³µ ë§ˆì´í¬ë¡œëª¨ë“ˆì˜ êµ¬ì„± ë°©ë²•ì€?",
    "ì´ìˆ˜êµ¬ë¶„ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?",
    "í•™ê³¼ë³„ ì „ê³µí•„ìˆ˜ êµê³¼ëª©ì€ ëª‡ í•™ì ì¸ê°€ìš”?",
]
for q in example_questions:
    if st.sidebar.button(q):
        st.session_state["example_query"] = q

# ====================================
# ğŸ’¬ ë©”ì¸ ì±—ë´‡ UI
# ====================================

st.title("ğŸ“ ìº í¼ìŠ¤ íŒŒì¸ë” RAG ì±—ë´‡")
st.markdown("í•™êµ ê³µì‹ í˜ì´ì§€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤ ğŸ«")

# âœ… ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
vectorstore = load_vectorstore()
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})  # ê²€ìƒ‰ í­ í™•ì¥
llm = ChatUpstage(model="solar-pro")
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff",
    return_source_documents=True,
)

# âœ… ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# âœ… ì…ë ¥
query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")

if "example_query" in st.session_state:
    query = st.session_state.pop("example_query")

if query:
    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... ğŸ”"):
        result = qa_chain.invoke({"query": query})
        answer = result["result"]
        sources = result.get("source_documents", [])
        st.session_state.chat_history.append({
            "user": query,
            "bot": answer,
            "sources": [d.metadata.get("source", "(unknown)") for d in sources]
        })

# âœ… ëŒ€í™” í‘œì‹œ
for chat in st.session_state.chat_history:
    st.chat_message("user").markdown(f"**ğŸ™‹â€â™‚ï¸ ì§ˆë¬¸:** {chat['user']}")
    st.chat_message("assistant").markdown(f"**ğŸ¤– ë‹µë³€:** {chat['bot']}")
    if chat["sources"]:
        with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ"):
            for s in chat["sources"]:
                st.markdown(f"- {s}")

# âœ… ì €ì¥ ë²„íŠ¼
if st.sidebar.button("ğŸ’¾ ëŒ€í™” ë‚´ìš© ì €ì¥"):
    with open("chat_history.txt", "w", encoding="utf-8") as f:
        for chat in st.session_state.chat_history:
            f.write(f"[USER] {chat['user']}\n[AI] {chat['bot']}\n\n")
    st.sidebar.success("ğŸ’¾ ëŒ€í™” ë‚´ìš©ì´ 'chat_history.txt'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
