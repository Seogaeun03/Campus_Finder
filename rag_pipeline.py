import os
from dotenv import load_dotenv

# âœ… ë³€ê²½ëœ import ê²½ë¡œ ë°˜ì˜
from langchain_community.vectorstores import Chroma
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA


# âœ… .env íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
api_key = os.getenv("UPSTAGE_API_KEY")

if not api_key:
    raise ValueError("âŒ Upstage API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”!")

# âœ… 1. ì„ë² ë”© ëª¨ë¸ (Solar Embedding)
embedding = UpstageEmbeddings(model="solar-embedding-1-large")

# âœ… 2. í¬ë¡¤ë§ëœ í…ìŠ¤íŠ¸ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
folder_path = "Result_crawling"
documents = []
for filename in os.listdir(folder_path):
    if filename.endswith(".txt"):
        with open(os.path.join(folder_path, filename), "r", encoding="utf-8") as f:
            documents.append(f.read())

# âœ… 3. í…ìŠ¤íŠ¸ë¥¼ chunk ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°
splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
texts = []
for doc in documents:
    texts.extend(splitter.split_text(doc))

# âœ… 4. Chroma DB ìƒì„± ë° ì €ì¥
vectorstore = Chroma.from_texts(texts, embedding=embedding, persist_directory="chroma_db")
print("âœ… ë²¡í„° DB ìƒì„± ì™„ë£Œ!")

# âœ… 5. Solar Pro ëª¨ë¸ë¡œ QA Chain êµ¬ì„±
llm = ChatUpstage(model="solar-pro")
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type="stuff")

# âœ… 6. ì‚¬ìš©ì ì…ë ¥ ë°›ì•„ì„œ ì§ˆì˜ì‘ë‹µ
print("\nğŸ“ ìº í¼ìŠ¤ íŒŒì¸ë” RAG ì±—ë´‡ ì‹œì‘!")
while True:
    query = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit'): ")
    if query.lower() == "exit":
        break
    result = qa_chain.invoke({"query": query})
    print(f"\nğŸ’¬ ë‹µë³€: {result['result']}")
